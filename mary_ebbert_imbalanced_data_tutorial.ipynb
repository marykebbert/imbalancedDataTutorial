{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Imbalanced Data in Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Introduction\n",
    "\n",
    "### What is imbalanced data and why is it a problem?\n",
    "Imbalanced data is a frequent and significant challenge for classification problems.\n",
    "\n",
    "Imbalanced datasets are those in which the classes are not equally represented. One such example would be a dataset where 95% of observations originate from one class and only 5% belong to the other. Common examples of situations in which imbalanced data is present are fraud dectection, medical diagnoses, and anomaly detection. Unless properly accounted for, this imbalance can cause the model to be biased towards the majority class and perform much more poorly on the minority class.  \n",
    "\n",
    "Thus, in this tutorial, we will cover various methods of dealing with imbalanced data in python.\n",
    "\n",
    "### Methods of dealing with imbalanced data\n",
    "There are several ways to deal with imbalanced data in Python. Some of the most common are the following:\n",
    "\n",
    "1. **Undersampling**: This involves reducing the occurences of the majority class to match the number of those in the minority class. This is typically done by randomly removing occurences of the majority class until the classes are equally represented in the data. A significant drawback to this approach is that, by removing a large proportion of the data, we are losing valuable information about the major class.\n",
    "\n",
    "2. **Oversampling**: This is, in many ways, the opposite of undersampling. Instead of removing occurences of the majority class, we are increasing the occurences of the minority class. The simplest approach to this method is to duplicate existing samples. However, other techniques have been developed to generate synthetic examples of the minority class. One popular example of this kind of oversampling is **SMOTE** (see bullet point below). If the duplicated observations or synthetic examples are not representative of the minority class, this leads to overfitting and poor generalization of the trained model.\n",
    "\n",
    "3. **Synthetic Minority Over-Sampling Technique (SMOTE)**: As explained above, this is a popular oversampling technique that involves generating synthetic examples for the minority class by interpolating between existing observations in the dataset. This reduces the risk of overfitting as it the examples it generates are more representative of the minority class than duplicates of existing observations would be. However, this method can take a long time to run due to its lengthy and complex task of generating large amounts of new data.  \n",
    "\n",
    "4. **A combination of undersampling and oversampling**: This technique uses a combination of undersampling and oversampling to acheive a balanced dataset. Typically, this is done by first using an undersampling technique to reduce the occurences of the majority class, followed by an oversampling technique to increase the occurences of the minority class. One common method in the imbalanced learn library is SMOTEENN.  \n",
    "\n",
    "5. **Class Weighting**: By giving the observations of the minority class more weight (often done by setting the `class_weight` parameter of the classifier to `'balanced'`), the classifier will pay more attention to the minority class during training, thus improving its ability to predict the minority class. However, this often results in higher false positive rates for the minority class (or worse ability to predict the majority class).\n",
    "\n",
    "In this tutorial, I will take you through some basic examples of the first three using a logistic regression classifier. \n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial\n",
    "For illustration purposes, I will use the flights dataset used during last project. In this dataset, the feature 'DEP_DEL15' is the response variable where 1 indicates that a flight was delayed more than 15 minutes and 0 otherwise. As shown below, there are only about 200,000 cases of fraud compared to 1 million cases of no fraud. \n",
    "\n",
    "### Load the data\n",
    "Feel free to go back to the repository where you can find the flights dataset and load into your python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"train_data.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data\n",
    "Before fitting any models, let us take a look at the data. According to the description in the repository, there are several columns that describe the flight logistics and plane details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1028946\n",
       "1     237295\n",
       "Name: DEP_DEL15, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"DEP_DEL15\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>DEP_DEL15</th>\n",
       "      <th>DEP_TIME_BLK</th>\n",
       "      <th>DISTANCE_GROUP</th>\n",
       "      <th>SEGMENT_NUMBER</th>\n",
       "      <th>CONCURRENT_FLIGHTS</th>\n",
       "      <th>NUMBER_OF_SEATS</th>\n",
       "      <th>CARRIER_NAME</th>\n",
       "      <th>AIRPORT_FLIGHTS_MONTH</th>\n",
       "      <th>...</th>\n",
       "      <th>PLANE_AGE</th>\n",
       "      <th>DEPARTING_AIRPORT</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>PREVIOUS_AIRPORT</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>AWND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2200-2259</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>90</td>\n",
       "      <td>Comair Inc.</td>\n",
       "      <td>11965</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Ronald Reagan Washington National</td>\n",
       "      <td>38.852</td>\n",
       "      <td>-77.037</td>\n",
       "      <td>Memphis International</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000-2059</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>180</td>\n",
       "      <td>Delta Air Lines Inc.</td>\n",
       "      <td>10714</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Minneapolis-St Paul International</td>\n",
       "      <td>44.886</td>\n",
       "      <td>-93.218</td>\n",
       "      <td>Stapleton International</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>6.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1800-1859</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>92</td>\n",
       "      <td>50</td>\n",
       "      <td>American Eagle Airlines Inc.</td>\n",
       "      <td>28583</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>Chicago O'Hare International</td>\n",
       "      <td>41.978</td>\n",
       "      <td>-87.906</td>\n",
       "      <td>Rochester Municipal</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>7.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1600-1659</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>129</td>\n",
       "      <td>Delta Air Lines Inc.</td>\n",
       "      <td>34238</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>Atlanta Municipal</td>\n",
       "      <td>33.641</td>\n",
       "      <td>-84.427</td>\n",
       "      <td>Jacksonville International</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>6.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-1959</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>173</td>\n",
       "      <td>United Air Lines Inc.</td>\n",
       "      <td>28904</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Chicago O'Hare International</td>\n",
       "      <td>41.978</td>\n",
       "      <td>-87.906</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>10.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MONTH  DAY_OF_WEEK  DEP_DEL15 DEP_TIME_BLK  DISTANCE_GROUP  SEGMENT_NUMBER  \\\n",
       "0      3            4          0    2200-2259               2               8   \n",
       "1      2            1          0    2000-2059               2               6   \n",
       "2      9            1          1    1800-1859               3               8   \n",
       "3      5            3          0    1600-1659               3               3   \n",
       "4      6            7          0    1900-1959               2               1   \n",
       "\n",
       "   CONCURRENT_FLIGHTS  NUMBER_OF_SEATS                  CARRIER_NAME  \\\n",
       "0                  21               90                   Comair Inc.   \n",
       "1                  44              180          Delta Air Lines Inc.   \n",
       "2                  92               50  American Eagle Airlines Inc.   \n",
       "3                  72              129          Delta Air Lines Inc.   \n",
       "4                  56              173         United Air Lines Inc.   \n",
       "\n",
       "   AIRPORT_FLIGHTS_MONTH  ...  PLANE_AGE                  DEPARTING_AIRPORT  \\\n",
       "0                  11965  ...          5  Ronald Reagan Washington National   \n",
       "1                  10714  ...          6  Minneapolis-St Paul International   \n",
       "2                  28583  ...         21       Chicago O'Hare International   \n",
       "3                  34238  ...         11                  Atlanta Municipal   \n",
       "4                  28904  ...          6       Chicago O'Hare International   \n",
       "\n",
       "   LATITUDE  LONGITUDE            PREVIOUS_AIRPORT  PRCP  SNOW SNWD  TMAX  \\\n",
       "0    38.852    -77.037       Memphis International  0.00   0.0  0.0  64.0   \n",
       "1    44.886    -93.218     Stapleton International  0.01   0.0  0.0  81.0   \n",
       "2    41.978    -87.906         Rochester Municipal  0.00   0.0  0.0  74.0   \n",
       "3    33.641    -84.427  Jacksonville International  0.00   0.0  0.0  84.0   \n",
       "4    41.978    -87.906                        NONE  0.38   0.0  0.0  81.0   \n",
       "\n",
       "    AWND  \n",
       "0   8.50  \n",
       "1   6.93  \n",
       "2   7.83  \n",
       "3   6.71  \n",
       "4  10.29  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a training and test set\n",
    "\n",
    "Using the sklearn `train_test_split` method, we can reserve 20% of the data to obtain unbaised metrics of our model's performance. As the dataset is greatly imbalanced, we will shuffle the data so that random allocation is perserved. Additionally, we will scale the data and change all the categorical data into 1s and 0s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "df = df.sample(frac=1, random_state=27)\n",
    "\n",
    "X = df.drop('DEP_DEL15', axis=1)\n",
    "y = df['DEP_DEL15']\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,\n",
    "                                                y,\n",
    "                                                test_size=0.2,\n",
    "                                                random_state=20)\n",
    "\n",
    "categorical_features = Xtrain.select_dtypes('object').columns\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "Xtrain_c = preprocessor.fit_transform(Xtrain)\n",
    "Xtest_c = preprocessor.transform(Xtest)\n",
    "\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "Xtrain = scaler.fit_transform(Xtrain_c)\n",
    "Xtest = scaler.transform(Xtest_c)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting our first model\n",
    "Here we will fit a simple, Logistic Regression model to obtain the baseline performance for a model on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=500)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(max_iter=500)\n",
    "\n",
    "clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating model performance\n",
    "When dealing with imbalance data, accuracy is not always a good metric to use to evaluate model performance. This is because a model can achieve high accuracy by simply predicting the majority class every time.\n",
    "\n",
    "Instead, the following metrics will be more useful to us:  \n",
    "- Precision: This is the proportion of true positives among all predicted positives.  \n",
    "$\\text{Precision} = \\text{True Positive} / \\text{True Positive + False Positive}$  \n",
    "- Recall: This is the proportion of true positives among all positives in the dataset.  \n",
    "$\\text{Recall} = \\text{True Positive} / \\text{True Positive + False Negative}$   \n",
    "- F1 Score: This is the harmonic mean of precision and recall.  \n",
    "$\\text{F1} = 2*(\\text{Precision} * \\text{Recall}) / (\\text{Precision} + \\text{Recall})$  \n",
    "\n",
    "Let's now evaluate how well the above model performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate(model, Xtest, ytest):\n",
    "    ypred = model.predict(Xtest)\n",
    "    report = classification_report(ytest, ypred, digits=4)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8130    1.0000    0.8968    205876\n",
      "           1     0.9091    0.0002    0.0004     47373\n",
      "\n",
      "    accuracy                         0.8130    253249\n",
      "   macro avg     0.8610    0.5001    0.4486    253249\n",
      "weighted avg     0.8310    0.8130    0.7292    253249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(clf, Xtest, ytest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described in this report, the model basically always predicts that the flight will not be delayed, as seen in the f1-score of 0. To fix this, we can try out various techniques for dealing with imbalanced data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with imbalanced data  \n",
    "Now that we have our dataset and evaluation metrics set up, let's explore the techniques dicussed prior for dealing with imbalanced data. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling\n",
    "As a reminder, undersampling involves reducing the number of examples in the majority class to match the number of examples in the minority class. \n",
    "\n",
    "We will first do this using the `RandomUnderSampler` from the `imbalanced-learn` library. This will randomly remove instances from the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    189922\n",
       "1    189922\n",
       "Name: DEP_DEL15, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "Xtrain_under_sampled, ytrain_under_sampled = RandomUnderSampler(random_state=27).fit_resample(Xtrain, ytrain)\n",
    "\n",
    "ytrain_under_sampled.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the `RandomUnderSampler` removed enough observations from the majority class (no delay) such that there is now an equal occurrence of both classes. \n",
    "Let's now see how the model performs on this resampled training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8744    0.5737    0.6928    205876\n",
      "           1     0.2573    0.6418    0.3673     47373\n",
      "\n",
      "    accuracy                         0.5864    253249\n",
      "   macro avg     0.5658    0.6077    0.5301    253249\n",
      "weighted avg     0.7589    0.5864    0.6319    253249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_under_sampled = LogisticRegression(max_iter=500)\n",
    "log_under_sampled.fit(Xtrain_under_sampled, ytrain_under_sampled)\n",
    "evaluate(log_under_sampled, Xtest, ytest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immediately, we can see that the model is now picking up instances of the minority class as the f1-score is 0.37. However, this has come at the cost of lower accuracy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampling\n",
    "As mentioned before, oversampling involves duplicating (or creating new) instances of the minority class to match the number of instances of the majority class. \n",
    "\n",
    "We will do this using the `RandomOverSampler` from the `imbalanced-learn` library. This will randomly duplicate instances from the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    823070\n",
       "1    823070\n",
       "Name: DEP_DEL15, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "Xtrain_over_sampled, ytrain_over_sampled = RandomOverSampler(random_state=27).fit_resample(Xtrain, ytrain)\n",
    "ytrain_over_sampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8739    0.5760    0.6943    205876\n",
      "           1     0.2574    0.6387    0.3669     47373\n",
      "\n",
      "    accuracy                         0.5877    253249\n",
      "   macro avg     0.5656    0.6074    0.5306    253249\n",
      "weighted avg     0.7586    0.5877    0.6331    253249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_over_sampled = LogisticRegression()\n",
    "log_over_sampled.fit(Xtrain_over_sampled, ytrain_over_sampled)\n",
    "evaluate(log_over_sampled, Xtest, ytest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling in this manner has also improved the model from before resampling. It has acheived near identical results as undersampling."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE\n",
    "SMOTE (Synthetic Minority Over-Sampling Technique) is a method that creates synthetic minority class observations until the class distribution is equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    823070\n",
       "1    823070\n",
       "Name: DEP_DEL15, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "Xtrain_smote, ytrain_smote = SMOTE(random_state=27).fit_resample(Xtrain, ytrain)\n",
    "\n",
    "ytrain_over_sampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8740    0.5778    0.6957    205876\n",
      "           1     0.2580    0.6381    0.3675     47373\n",
      "\n",
      "    accuracy                         0.5891    253249\n",
      "   macro avg     0.5660    0.6080    0.5316    253249\n",
      "weighted avg     0.7588    0.5891    0.6343    253249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_smote = LogisticRegression(max_iter=500)\n",
    "log_smote.fit(Xtrain_smote, ytrain_smote)\n",
    "evaluate(log_smote, Xtest, ytest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A combination of over- and under-sampling  \n",
    "Another way to deal with imbalanced data is to combine over- and under- sampling data. One such method is called SMOTEENN. This is a method in the imbalanced learn library that uses SMOTE to over-sample and another method called Edited Nearest Neighbours to clean (under-sample) the data.  \n",
    "\n",
    "The syntax is as follows (this took my computer 15 hours to run):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    823070\n",
       "1    823070\n",
       "Name: DEP_DEL15, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "Xtrain_sme, ytrain_sme = SMOTEENN(random_state=27).fit_resample(Xtrain, ytrain)\n",
    "\n",
    "ytrain_over_sampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8239    0.9364    0.8766    205876\n",
      "           1     0.3208    0.1305    0.1855     47373\n",
      "\n",
      "    accuracy                         0.7857    253249\n",
      "   macro avg     0.5724    0.5334    0.5310    253249\n",
      "weighted avg     0.7298    0.7857    0.7473    253249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_sme = LogisticRegression(max_iter=500)\n",
    "log_sme.fit(Xtrain_sme, ytrain_sme)\n",
    "evaluate(log_sme, Xtest, ytest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the model fit on the SMOTEENN data took several hours to run, it did not result in a signficantly better model than the other methods dicussed above. It did give a better precision metric than the other resampling techniques but got a much lower recall and f1-score."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Weighting\n",
    "\n",
    "In many classification models, there is the option to specify a `class_weight` parameter. If this is set to `balanced`, it means that the model will give more weight to the minority class and less to the majority class. This means that the model will penalize the misclassification of the minority class more than the majority class, leading to better predictions of the minority class.  \n",
    "\n",
    "For logisitic regression, we do the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8744    0.5758    0.6943    205876\n",
      "           1     0.2578    0.6405    0.3677     47373\n",
      "\n",
      "    accuracy                         0.5879    253249\n",
      "   macro avg     0.5661    0.6082    0.5310    253249\n",
      "weighted avg     0.7591    0.5879    0.6332    253249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_class_weights = LogisticRegression(class_weight='balanced')\n",
    "log_class_weights.fit(Xtrain, ytrain)\n",
    "evaluate(log_class_weights, Xtest, ytest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting `class_weight='balanced'` significantly improved the model from a base model without it. It is a very simple and fast way to adjust for imbalanced data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping Up\n",
    "Surprisingly, all resampling techniques but SMOTEEN yielded very similar results. Likely, the relative performance of these will vary depending on the data. Additionally, these comparisons were only performed with a simple logistic regression model. It is very likely that the effect of resampling will be different for different models as well.\n",
    "\n",
    "I encourage you to try these methods on your own data as what is best in one case may not be the best in every circumstance so it is a good idea to become familiar with the possibilities. For more information, check out the [imbalanced-learn documentation](https://imbalanced-learn.org/stable/user_guide.html#user-guide).\n",
    "\n",
    "As always, thank you for reading and feel free to let me know your thoughts, questions, ideas to improve, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
